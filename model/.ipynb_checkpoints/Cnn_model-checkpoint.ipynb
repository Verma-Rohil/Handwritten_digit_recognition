{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be97e53f-12fe-45ed-96e9-f7c61e731297",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261b88e-d68f-45ea-a75c-305c8a53dd8d",
   "metadata": {},
   "source": [
    "##### Name : Rohil Verma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8fd133-019c-4426-8a63-9dca98e974ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40bba149-98ad-4399-af8b-fc159b755d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6504b64-7aaf-44cc-a911-4f982160ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5719a737-1dc1-4593-81d7-f76d517999f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
      "training Dataset size : 25372\n",
      "testing Dataset size : 6343\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "            [transforms.Grayscale(num_output_channels=1),\n",
    "             transforms.Resize((28,28)),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5,),(0.5,))\n",
    "             ])\n",
    "\n",
    "dataset = datasets.ImageFolder(root= '../dataset/', transform= transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_set , test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size= 32 , shuffle= True)\n",
    "test_loader = DataLoader(test_set, batch_size= 32, shuffle= False)\n",
    "\n",
    "for images,labels in test_loader:\n",
    "    print(images.shape,labels.shape)\n",
    "    break\n",
    "\n",
    "print(f'training Dataset size : {len(train_set)}')\n",
    "print(f'testing Dataset size : {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e7e655-ee81-42e2-bddd-e45a9cda066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images,labels in train_loader:\n",
    "    plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "    plt.title(f'Label: {labels[0]}')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf927a6-91b0-42f0-ad93-cecd7a45654d",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e3dd761-88bb-41f5-960e-e130a287a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd88d08-381e-4599-a80f-27d651e20354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNmodel,self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 32, kernel_size= 3, stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size= 3, stride=1,padding=1)\n",
    "\n",
    "        # pooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64*7*7,128) \n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolution -> ReLU -> Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # for flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f223aa-11b0-4b00-afe7-863aa508997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399646d-7ab7-4e8f-88d4-8f0560a74dd9",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b38d0b-a78c-4812-83c6-54f808df541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch : [1/10], Loss : 2.2795, Accuracy : 21.1059\n",
      " Epoch : [2/10], Loss : 1.6159, Accuracy : 49.0817\n",
      " Epoch : [3/10], Loss : 0.8032, Accuracy : 74.7517\n",
      " Epoch : [4/10], Loss : 0.4676, Accuracy : 85.2633\n",
      " Epoch : [5/10], Loss : 0.3148, Accuracy : 90.3437\n",
      " Epoch : [6/10], Loss : 0.2518, Accuracy : 92.3144\n",
      " Epoch : [7/10], Loss : 0.1897, Accuracy : 94.1904\n",
      " Epoch : [8/10], Loss : 0.1562, Accuracy : 95.2113\n",
      " Epoch : [9/10], Loss : 0.1329, Accuracy : 95.9246\n",
      " Epoch : [10/10], Loss : 0.1159, Accuracy : 96.4567\n"
     ]
    }
   ],
   "source": [
    "# Create model object\n",
    "Cnn_model = CNNmodel()\n",
    "\n",
    "# create loss_function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.SGD(Cnn_model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()         # Reset gradients\n",
    "        outputs = Cnn_model(images)   # forward pass\n",
    "        loss = loss_func(outputs, labels) # Computing loss\n",
    "        loss.backward()   # backward pass\n",
    "        optimizer.step()  # Updating grads\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_epoch_loss = running_loss/ len(train_loader)\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct/total)\n",
    "    print(f' Epoch : [{epoch+1}/{epochs}], Loss : {total_epoch_loss:.4f}, Accuracy : {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d515d5-65d3-4f83-9d66-8376b1885d72",
   "metadata": {},
   "source": [
    "# Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf025b98-e44c-4dd6-826e-28731e01538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 96.3740\n"
     ]
    }
   ],
   "source": [
    "Cnn_model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in train_loader:\n",
    "        outputs = Cnn_model(images)\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        total+= labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "\n",
    "accuracy = 100 * (correct/total)\n",
    "print(f'Train Accuracy : {accuracy:.4f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ca2ea2-c292-4853-a6b0-bf39bad501d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 95.0339\n"
     ]
    }
   ],
   "source": [
    "Cnn_model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        outputs = Cnn_model(images)\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        total+= labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "\n",
    "accuracy = 100 * (correct/total)\n",
    "print(f'Test Accuracy : {accuracy:.4f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef9b6d-d703-4334-a544-54976bef256a",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6032d8-990e-4625-ac81-ec9330e0e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Cnn_model.state_dict(), \"../model/Cnn_digit_recognition.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de7db3-30f7-4a9a-bdfb-897e93a188b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (handwritten_digit_recognition)",
   "language": "python",
   "name": "handwritten_digit_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
