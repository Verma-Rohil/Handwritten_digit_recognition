{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48b5269-e407-4cd2-aa1a-0fa9d3fa6197",
   "metadata": {},
   "source": [
    "# Hand written digit recognition through ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d456dc9-b48e-4802-82a3-409a15248932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738a680-2fe2-4c73-9af1-dc0772156ac3",
   "metadata": {},
   "source": [
    "# Image processing and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2268dbd5-1d3d-444a-bc01-6cfefde02464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, direc):\n",
    "        self.direc = direc\n",
    "        self.data = []  # Stores (image, label) pairs\n",
    "        self.tranform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5,),(0.5,)),  # Normalized from (0,255) to [-1,1] for better training stability\n",
    "             transforms.RandomRotation(10),        # Rotate image randomly\n",
    "             transforms.RandomHorizontalFlip()])    # Flip image randomly])\n",
    "                                                                                         \n",
    "        \n",
    "\n",
    "        for label in range(10):\n",
    "            Folder_path = os.path.join(direc, str(label))  # # e.g., dataset/0, dataset/1, ...\n",
    "            if not os.path.exists(Folder_path):\n",
    "                continue\n",
    "\n",
    "            for img_name in os.listdir(Folder_path):\n",
    "                img_path = os.path.join(Folder_path, img_name) # the folder path is joined by image name...\n",
    "\n",
    "\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # all images have been loaded into img\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = cv2.resize(img, (28,28)) \n",
    "                img = self.tranform(img) # transformation applied to the images\n",
    "\n",
    "                self.data.append((img,label)) # whole img with their label is appended into data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]    # Returns (image, label) pair\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f0ff4a-1872-44ff-b908-d5e1b8227e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31715"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"../dataset/\"\n",
    "\n",
    "digit_data = CustomDataset(image_path)\n",
    "len(digit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb23f09-4aa6-4ae2-b38f-7bb0c2df216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0: Shape = torch.Size([1, 28, 28]), Label = 0\n",
      "Image 1: Shape = torch.Size([1, 28, 28]), Label = 0\n",
      "Image 2: Shape = torch.Size([1, 28, 28]), Label = 0\n",
      "Image 3: Shape = torch.Size([1, 28, 28]), Label = 0\n",
      "Image 4: Shape = torch.Size([1, 28, 28]), Label = 0\n",
      "Total Dataset Size: 31715\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    img, label = digit_data[i]\n",
    "    print(f\"Image {i}: Shape = {img.shape}, Label = {label}\")\n",
    "\n",
    "# Verify Train/Test Split\n",
    "print(f\"Total Dataset Size: {len(digit_data)}\")\n",
    "# print(f\"Training Set Size: {len(train_dataset)}\")\n",
    "# print(f\"Testing Set Size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9922cc-ac3c-4c3c-b0b9-0ba167cf439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Total images loaded: {len(digit_data)}\")\n",
    "\n",
    "# # Example: Fetch first image & label\n",
    "# sample_img, sample_label = digit_data[0]\n",
    "# print(f\"Sample image shape: {sample_img}, Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37864c-d73e-407e-8dc7-c8fe9ae5ee4d",
   "metadata": {},
   "source": [
    "# ANN Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34641c-9eea-4f49-8c33-7341836e3653",
   "metadata": {},
   "source": [
    "### Tasks to be done to create the model:\n",
    "1. As we have prepared the dataset(digit_data), Now we have to split this data into train and test dataset.\n",
    "2. we will use DataLoader For batch processing.\n",
    "3. Then we will define the ANN model.\n",
    "### Model Training:\n",
    "1. we will assume learning_rate(0.1) and epochs.\n",
    "2. Create loss function, generate optimizers.\n",
    "3. running epochs in training data.\n",
    "4. Calculate loss and accuracy for each epoch, So that we could understand how the model is working.\n",
    "#### Finally evaluate the model by running it on test_data and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee120f8-2676-4d75-a411-344957b98b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training images : 25372 \n",
      " Number of testing images : 6343 \n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(digit_data))\n",
    "test_size = len(digit_data) - train_size\n",
    "\n",
    "train_dataset , test_dataset = random_split(dataset= digit_data, lengths= [train_size, test_size])\n",
    "\n",
    "print(f' Number of training images : {len(train_dataset)} ')\n",
    "print(f' Number of testing images : {len(test_dataset)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5489435-6646-4ddf-b7e4-d1b7e1f64665",
   "metadata": {},
   "source": [
    "# Using Dataloader for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc8afbd-7b0b-4a51-b9b1-649cd9d3cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True)\n",
    "test_loader = DataLoader(test_dataset, batch_size= 32, shuffle= False)\n",
    "\n",
    "for images,labels in test_loader:\n",
    "    for i in range(6):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Label: {labels[i].item()}\")\n",
    "        plt.axis('off')\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17522643-1b33-43f8-972e-b029e1ab0489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4647e5-25e0-4cd4-915c-6af08e106db3",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f512e503-f840-4b85-a104-475fc944fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ANNmodel(nn.Module):\n",
    "#     def __init__(self, num_features):\n",
    "#         super().__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             nn.Linear(num_features,128),\n",
    "#             # nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.Dropout(0.2),\n",
    "#             nn.Linear(128,64),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.Dropout(0.2),\n",
    "#             nn.Linear(64,10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, features):\n",
    "#         out = self.network(features)\n",
    "\n",
    "#         return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35b445d-0cf0-4921-bc9f-bc141b60b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ann_model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "                nn.Linear(num_features,224),\n",
    "                # nn.BatchNorm1d(224),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout(0.1),\n",
    "                nn.Linear(224,64),\n",
    "                # nn.BatchNorm1d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,96),\n",
    "                # nn.BatchNorm1d(96),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(96,192),\n",
    "                # nn.BatchNorm1d(192),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(192,10))\n",
    "\n",
    "    def forward(self,features):\n",
    "        out = self.network(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a407b9fa-c003-4e9e-ab51-0d07d061e50c",
   "metadata": {},
   "source": [
    "ANNModel(\n",
    "  (network): Sequential(\n",
    "    (0): Linear(in_features=784, out_features=224, bias=True)\n",
    "    (1): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): Linear(in_features=224, out_features=64, bias=True)\n",
    "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (5): ReLU()\n",
    "    (6): Linear(in_features=64, out_features=96, bias=True)\n",
    "    (7): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (8): ReLU()\n",
    "    (9): Linear(in_features=96, out_features=192, bias=True)\n",
    "    (10): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (11): ReLU()\n",
    "    (12): Linear(in_features=192, out_features=10, bias=True)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21820923-fc81-408a-8bcc-c7bbe1046947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image,label = train_dataset[0]\n",
    "height,width = image.shape[1],image.shape[2]\n",
    "num_features = height*width\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76f4ac8-cb9e-4448-abf4-9cb34efe2407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ann_model(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=224, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=224, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=96, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=96, out_features=192, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=192, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ann_model(num_features)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da07a8b-13a8-4763-9220-1b44517b28a2",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b75c7b-50e4-4d94-a79f-1182631a84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.002\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25472f33-ffe2-42cb-b44c-bd6c59faa379",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizers = torch.optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85dcde76-e0ff-4802-a455-ae443186a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff49917-b814-4748-a207-f6faa5212059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/30], Loss : 1.71, Epoch Accuracy : 37.8015\n",
      "Epoch : [2/30], Loss : 1.43, Epoch Accuracy : 49.8266\n",
      "Epoch : [3/30], Loss : 1.32, Epoch Accuracy : 54.1502\n",
      "Epoch : [4/30], Loss : 1.23, Epoch Accuracy : 57.4610\n",
      "Epoch : [5/30], Loss : 1.15, Epoch Accuracy : 60.4643\n",
      "Epoch : [6/30], Loss : 1.08, Epoch Accuracy : 63.0892\n",
      "Epoch : [7/30], Loss : 1.02, Epoch Accuracy : 65.2215\n",
      "Epoch : [8/30], Loss : 0.97, Epoch Accuracy : 66.7823\n",
      "Epoch : [9/30], Loss : 0.91, Epoch Accuracy : 68.5283\n",
      "Epoch : [10/30], Loss : 0.86, Epoch Accuracy : 70.5699\n",
      "Epoch : [11/30], Loss : 0.83, Epoch Accuracy : 71.1493\n",
      "Epoch : [12/30], Loss : 0.81, Epoch Accuracy : 72.4736\n",
      "Epoch : [13/30], Loss : 0.77, Epoch Accuracy : 73.5299\n",
      "Epoch : [14/30], Loss : 0.73, Epoch Accuracy : 74.5743\n",
      "Epoch : [15/30], Loss : 0.72, Epoch Accuracy : 75.3705\n",
      "Epoch : [16/30], Loss : 0.70, Epoch Accuracy : 75.7489\n",
      "Epoch : [17/30], Loss : 0.68, Epoch Accuracy : 76.5371\n",
      "Epoch : [18/30], Loss : 0.66, Epoch Accuracy : 76.8485\n",
      "Epoch : [19/30], Loss : 0.64, Epoch Accuracy : 77.6013\n",
      "Epoch : [20/30], Loss : 0.66, Epoch Accuracy : 77.4121\n",
      "Epoch : [21/30], Loss : 0.62, Epoch Accuracy : 78.3817\n",
      "Epoch : [22/30], Loss : 0.61, Epoch Accuracy : 78.6300\n",
      "Epoch : [23/30], Loss : 0.60, Epoch Accuracy : 79.0872\n",
      "Epoch : [24/30], Loss : 0.60, Epoch Accuracy : 79.3355\n",
      "Epoch : [25/30], Loss : 0.58, Epoch Accuracy : 79.7887\n",
      "Epoch : [26/30], Loss : 0.57, Epoch Accuracy : 80.3642\n",
      "Epoch : [27/30], Loss : 0.57, Epoch Accuracy : 80.5494\n",
      "Epoch : [28/30], Loss : 0.56, Epoch Accuracy : 80.6401\n",
      "Epoch : [29/30], Loss : 0.55, Epoch Accuracy : 80.9514\n",
      "Epoch : [30/30], Loss : 0.53, Epoch Accuracy : 81.4086\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_epoch_loss = 0\n",
    "    for images , labels in train_loader:\n",
    "        # Flatten images (MNIST images are 28x28)\n",
    "        # images = images.view(-1, 28*28)\n",
    "        images = images.view(images.size(0), -1)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # calculate loss \n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward pass\n",
    "        optimizers.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update grads\n",
    "        optimizers.step()\n",
    "\n",
    "        total_epoch_loss = total_epoch_loss + loss.item()\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "\n",
    "    avg_loss = total_epoch_loss/len(train_loader)\n",
    "    epoch_accuracy = 100 * (correct/total)\n",
    "\n",
    "    print(f\"Epoch : [{epoch + 1}/{epochs}], Loss : {avg_loss:.2f}, Epoch Accuracy : {epoch_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "699d7b61-193c-4179-a18f-e84dd12ed7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 80.72%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total =  0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        # labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print(f\"Predict: {predicted}, Lable: {label}\")\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Train Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fb382a5-38de-46e2-a9c0-7d03e4edb505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.72%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total =  0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        # labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print(f\"Predict: {predicted}, Lable: {label}\")\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b2206dc-b2fa-4e9c-9a55-5b6c8e3750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464f57e5-bf59-4a6b-af05-5dc02305be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model/Ann_digit_recognition.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550bd6d-8995-40ba-a269-9d391f813bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (handwritten_digit_recognition)",
   "language": "python",
   "name": "handwritten_digit_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
